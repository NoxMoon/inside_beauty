{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape beauty product infomation from [beautypedia](beautypedia.com), a website where Paula Begoun and her team post their review on beauty products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import re\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect product links from main page. The product links are dynamically generated and cannot be found in html sourse file using requests package. We will use selenium to simulate browsers and get the links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product_links(start_page):\n",
    "    product_links = []\n",
    "    product_names = []\n",
    "\n",
    "    browser = webdriver.Firefox()\n",
    "    browser.get(start_page)\n",
    "\n",
    "    # select 96 items per page so we can loop less pages\n",
    "    el = browser.find_element_by_class_name('results-per-page')\n",
    "    for option in el.find_elements_by_tag_name('option'):\n",
    "        if option.text == '96':\n",
    "            option.click() # select() in earlier versions of webdriver\n",
    "            break\n",
    "\n",
    "    # find how many pages we have to loop\n",
    "    i=1\n",
    "    npage = int(browser.find_element_by_class_name(\"archive-pagination-select\").text.replace('\\n',' ').split()[-1])\n",
    "    print('page (%d total) - first product'%npage)\n",
    "    while True:\n",
    "        soup = BeautifulSoup(browser.page_source,\"html5lib\")\n",
    "        links = soup.find_all('a',class_=\"review-product\")\n",
    "        print(\"%6d  %s\"%(i, links[0].text))\n",
    "        product_links += [link['href'] for link in links]\n",
    "        product_names += [link.text for link in links]\n",
    "        if i==npage:\n",
    "            break\n",
    "        else:\n",
    "            time.sleep(5)  # wait a few seconds -- be gentle to the server\n",
    "            browser.find_element_by_class_name('next-page').click() #click next-page button\n",
    "            i=i+1\n",
    "            time.sleep(5)\n",
    "    browser.close()\n",
    "    \n",
    "    return product_links, product_names\n",
    "\n",
    "def get_product_by_category(category_list, excluded_category):\n",
    "    \n",
    "    mega_data = pd.DataFrame()\n",
    "    for item in category_list:\n",
    "        category = item.text.replace('\\n','').replace('\\t','')\n",
    "        if category in excluded_category:\n",
    "            continue\n",
    "        print('collecting data for ', category)\n",
    "        product_links, product_names = get_product_links(item['href'])\n",
    "        df = pd.DataFrame({'product_links':product_links, 'product_names':product_names, 'product_category':category})\n",
    "        mega_data = mega_data.append(df)\n",
    "\n",
    "    mega_data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return mega_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to each product's page and collect information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_product(mega_data, image_folder=\"images/\"):\n",
    "    \n",
    "    if not os.path.isdir(image_folder):\n",
    "        os.system(\"mkdir \"+image_folder)\n",
    "    \n",
    "    mega_data['brand'] = None\n",
    "    mega_data['ingredient'] = None\n",
    "    mega_data['size'] = None\n",
    "    mega_data['price'] = None\n",
    "    mega_data['claims'] = None\n",
    "    mega_data['image_path'] = None\n",
    "\n",
    "    for i in tqdm(range(mega_data.shape[0])):\n",
    "        url = mega_data['product_links'].iloc[i]\n",
    "        r = requests.get(url)\n",
    "        soup = BeautifulSoup(r.text)\n",
    "\n",
    "        #brand\n",
    "        brand = soup.find('h2')\n",
    "        if brand is not None:\n",
    "            mega_data['brand'].iloc[i] = brand.text\n",
    "\n",
    "        #ingredient\n",
    "        ingredient = soup.find('div',class_=re.compile(\"content-item ingredients\"))\n",
    "        if ingredient is not None:\n",
    "            mega_data['ingredient'].iloc[i] = ingredient.text.strip()\n",
    "        \n",
    "        #size\n",
    "        size = soup.find('span', class_=re.compile(\"size\"))\n",
    "        if size is not None:\n",
    "            mega_data['size'].iloc[i] = size.text\n",
    "\n",
    "        #price\n",
    "        price = soup.find('span', class_=re.compile(\"price\"))\n",
    "        if price is not None:\n",
    "            mega_data['price'].iloc[i] = price.text\n",
    "            \n",
    "        #claims\n",
    "        claims = soup.find('div', id=\"claims\")\n",
    "        if claims is not None:\n",
    "            mega_data['claims'].iloc[i] = claims.text\n",
    "        \n",
    "        #image\n",
    "        img_url = soup.find('div', class_=\"product-image\").find('img')['src']\n",
    "        if img_url is not None:\n",
    "            try:\n",
    "                r_img = requests.get(img_url)\n",
    "            except requests.exceptions.ConnectionError:\n",
    "                time.sleep(2)\n",
    "            if r_img.status_code == 200:\n",
    "                image_path = image_folder+mega_data['product_names'].iloc[i].replace(' ','-').replace('/','-')+'_'+mega_data['brand'].iloc[i].replace(' ','-').replace('/','-')+'.jpg'\n",
    "                with open(image_path, 'wb') as f:\n",
    "                    f.write(r_img.content)\n",
    "                mega_data['image_path'].iloc[i] = image_path \n",
    "        \n",
    "        time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect skin care products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 1222/6182 [56:04<3:43:43,  2.71s/it]"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(\"skin_care_products.csv\"):\n",
    "    cols = ['product_names','product_category','brand','product_links']\n",
    "    skin_care_products = pd.read_csv('skin_care_products.csv', usecols=cols)\n",
    "else:\n",
    "    url = 'https://www.beautypedia.com/skin-care'\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text)\n",
    "    skin_care_cat = soup.find_all('a', class_=\"submenu-item\", href=re.compile('/skin-care/'))[:30]\n",
    "    excluded_category = ['Best & Worst Skin Care Products','Moisturizer']\n",
    "    skin_care_products = get_product_by_category(skin_care_cat, excluded_category)\n",
    "\n",
    "fetch_product(skin_care_products, image_folder=\"images/skin_care/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skin_care_products.to_csv('skin_care_products.csv',index=False)\n",
    "print(\"# of skin care products:\", skin_care_products.shape)\n",
    "skin_care_products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect body care products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if os.path.isfile(\"body_care_products.csv\"):\n",
    "    cols = ['product_names','product_category','brand','product_links']\n",
    "    body_care_products = pd.read_csv('body_care_products.csv', usecols=cols)\n",
    "else:\n",
    "    url = 'https://www.beautypedia.com/body-care'\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text)\n",
    "    body_care_cat = soup.find_all('a', class_=\"submenu-item\", href=re.compile('/body-care/'))[:6]\n",
    "    excluded_category = []\n",
    "    body_care_products = get_product_by_category(body_care_cat, excluded_category)\n",
    "\n",
    "fetch_product(body_care_products, image_folder=\"images/body_care/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_care_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_care_products.to_csv('body_care_products.csv',index=False)\n",
    "print(\"# of body care products:\", body_care_products.shape)\n",
    "body_care_products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect makeup products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if os.path.isfile(\"makeup_products.csv\"):\n",
    "    cols = ['product_names','product_category','brand','product_links']\n",
    "    makeup_products = pd.read_csv('makeup_products.csv', usecols=cols)\n",
    "else:\n",
    "    url = 'https://www.beautypedia.com/makeup'\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text)\n",
    "    makeup_cat = soup.find_all('a', class_=\"submenu-item\", href=re.compile('/makeup/'))[:28]\n",
    "    excluded_category = ['Best & Worst Makeup Products', 'Eyes', 'Lips', 'Face']\n",
    "    makeup_products = get_product_by_category(makeup_cat, excluded_category)\n",
    "\n",
    "fetch_product(makeup_products, image_folder=\"images/makeup/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "makeup_products.to_csv('makeup_products.csv',index=False)\n",
    "print(\"# of makeup products:\", makeup_products.shape)\n",
    "makeup_products.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
